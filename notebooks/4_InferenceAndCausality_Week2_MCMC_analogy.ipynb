{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd4ace0",
   "metadata": {},
   "source": [
    "# Monte Carlo & MCMC — The Garden Pond Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec386f7f",
   "metadata": {},
   "source": [
    "**Goal:** Estimate where/how big the hidden pond is by throwing stones. Monte Carlo = random throws; MCMC = smart, feedback-driven throws."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86229ebc",
   "metadata": {},
   "source": [
    "> *“When we can’t solve the integral, we start walking through it.”*\n",
    "\n",
    "In Bayesian inference, computing the **posterior** often means integrating over a huge, continuous space of possible parameter values.  \n",
    "When the math gets impossible to do exactly, we turn to clever **approximation by sampling**. This is where **Markov Chain Monte Carlo (MCMC)** comes in.\n",
    "\n",
    "MCMC algorithms (like Metropolis–Hastings or Gibbs sampling) create a **chain of samples** that, over time, behave as if they were drawn directly from the posterior distribution.\n",
    "\n",
    "In this notebook:\n",
    "- We’ll **build intuition** for how a Markov chain explores a distribution,  \n",
    "- Use a **simple analogy**  to visualize how it “learns” the shape of the target distribution,  \n",
    "- And see why this method is the backbone of modern Bayesian computation.\n",
    "\n",
    "The goal is **intuition, not math**! to understand *why* this approach works before diving into formulas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67839bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "rng = np.random.default_rng(42)\n",
    "GARDEN_X, GARDEN_Y = (0.0, 10.0), (0.0, 7.0)\n",
    "GARDEN_AREA = (GARDEN_X[1]-GARDEN_X[0])*(GARDEN_Y[1]-GARDEN_Y[0])\n",
    "pond_centers = np.array([[4.0, 3.5], [6.3, 3.0]])\n",
    "pond_radii   = np.array([1.5, 1.2])\n",
    "bulge_center = np.array([5.2, 4.4])\n",
    "bulge_axes   = np.array([1.0, 0.6])\n",
    "bulge_angle  = np.deg2rad(25.0)\n",
    "def inside_circles(xy):\n",
    "    return ((xy[:,0]-pond_centers[0,0])**2 + (xy[:,1]-pond_centers[0,1])**2 <= pond_radii[0]**2) |            ((xy[:,0]-pond_centers[1,0])**2 + (xy[:,1]-pond_centers[1,1])**2 <= pond_radii[1]**2)\n",
    "def inside_ellipse(xy):\n",
    "    c, s = np.cos(-bulge_angle), np.sin(-bulge_angle)\n",
    "    R = np.array([[c, -s],[s, c]])\n",
    "    v = (xy - bulge_center) @ R.T\n",
    "    return (v[:,0]/bulge_axes[0])**2 + (v[:,1]/bulge_axes[1])**2 <= 1.0\n",
    "def pond_indicator(xy):\n",
    "    return (inside_circles(xy) | inside_ellipse(xy)).astype(int)\n",
    "t = np.linspace(0, 2*np.pi, 180)\n",
    "edge_samples = np.vstack([\n",
    "    pond_centers[0] + np.column_stack([np.cos(t), np.sin(t)]) * pond_radii[0],\n",
    "    pond_centers[1] + np.column_stack([np.cos(t), np.sin(t)]) * pond_radii[1],\n",
    "    bulge_center + np.column_stack([bulge_axes[0]*np.cos(t), bulge_axes[1]*np.sin(t)]) @\n",
    "    np.array([[np.cos(bulge_angle), -np.sin(bulge_angle)],[np.sin(bulge_angle), np.cos(bulge_angle)]]).T\n",
    "])\n",
    "def splash_loudness(xy, sigma=0.25):\n",
    "    d = np.sqrt(((xy[:,None,:]-edge_samples[None,:,:])**2).sum(axis=-1)).min(axis=1)\n",
    "    return np.exp(-d/sigma) + 0.5 * pond_indicator(xy)\n",
    "def throw_stones_uniform(n):\n",
    "    xs = rng.uniform(GARDEN_X[0], GARDEN_X[1], size=n)\n",
    "    ys = rng.uniform(GARDEN_Y[0], GARDEN_Y[1], size=n)\n",
    "    pts = np.column_stack([xs, ys])\n",
    "    hits = pond_indicator(pts)\n",
    "    return pts, hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4277a8",
   "metadata": {},
   "source": [
    "## Part 1 — Pure Monte Carlo (uniform throws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d76b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8000\n",
    "pts, hits = throw_stones_uniform(N)\n",
    "cum_hits = np.cumsum(hits)\n",
    "est_area = (cum_hits / np.arange(1, N+1)) * GARDEN_AREA\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "show = min(N, 1000)\n",
    "ax.scatter(pts[:show,0], pts[:show,1], s=10, label=\"miss\")\n",
    "hm = hits[:show] == 1\n",
    "ax.scatter(pts[:show,0][hm], pts[:show,1][hm], s=12, label=\"hit\")\n",
    "ax.set_xlim(*GARDEN_X); ax.set_ylim(*GARDEN_Y)\n",
    "ax.set_title(\"Random throws: hits vs misses (first 1000)\")\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\")\n",
    "ax.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,3.5))\n",
    "ax.plot(est_area)\n",
    "ax.set_title(\"Monte Carlo estimate of pond area vs number of throws\")\n",
    "ax.set_xlabel(\"Number of throws\"); ax.set_ylabel(\"Estimated area\")\n",
    "plt.show()\n",
    "\n",
    "est_area[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f09cfb",
   "metadata": {},
   "source": [
    "## Part 2 — MCMC (smart throws via Metropolis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c823fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_chain(T=7000, step=0.30):\n",
    "    x = rng.uniform(*GARDEN_X); y = rng.uniform(*GARDEN_Y)\n",
    "    pts = np.empty((T,2)); acc = 0\n",
    "    for t in range(T):\n",
    "        cur = np.array([[x,y]]); cs = splash_loudness(cur)[0]\n",
    "        xn, yn = x + rng.normal(scale=step), y + rng.normal(scale=step)\n",
    "        xn = GARDEN_X[0] + abs((xn - GARDEN_X[0]) % (2*(GARDEN_X[1]-GARDEN_X[0])))\n",
    "        if xn > GARDEN_X[1]: xn = 2*GARDEN_X[1] - xn\n",
    "        yn = GARDEN_Y[0] + abs((yn - GARDEN_Y[0]) % (2*(GARDEN_Y[1]-GARDEN_Y[0])))\n",
    "        if yn > GARDEN_Y[1]: yn = 2*GARDEN_Y[1] - yn\n",
    "        ns = splash_loudness(np.array([[xn,yn]]))[0]\n",
    "        a = min(1.0, ns/(cs+1e-12))\n",
    "        if rng.uniform() < a: x, y, acc = xn, yn, acc+1\n",
    "        pts[t] = [x,y]\n",
    "    return pts, acc/T\n",
    "\n",
    "chain, acc_rate = metropolis_chain(T=7000, step=0.30)\n",
    "burn = 1000; chain_b = chain[burn:]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "th = chain_b[::10]\n",
    "ax.plot(th[:,0], th[:,1], linewidth=1.0)\n",
    "ax.set_xlim(*GARDEN_X); ax.set_ylim(*GARDEN_Y)\n",
    "ax.set_title(f\"MCMC trajectory after burn-in (acceptance ~ {acc_rate:.2f})\")\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "H, xedges, yedges = np.histogram2d(chain_b[:,0], chain_b[:,1], bins=(60,42),\n",
    "                                   range=[GARDEN_X, GARDEN_Y], density=True)\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "ax.imshow(H.T, origin='lower',\n",
    "          extent=[GARDEN_X[0], GARDEN_X[1], GARDEN_Y[0], GARDEN_Y[1]],\n",
    "          aspect='auto')\n",
    "ax.set_title(\"Where the chain spends time (higher ≈ more water)\")\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "# Compare time over water\n",
    "pts_mc, _ = throw_stones_uniform(3000)\n",
    "float( (pts_mc.shape[0] > 0) and ( ( ( (pts_mc.shape[0])**0 ) ) ) )  # harmless line to keep cell non-empty\n",
    "(pond_indicator(pts_mc).mean(), pond_indicator(chain_b).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade697e0",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "- Monte Carlo gives an unbiased area estimate but wastes throws on land.\n",
    "- MCMC uses feedback (Markov) to spend more time over water, mapping the pond's shape efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42413482",
   "metadata": {},
   "source": [
    "## Excersice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9749662",
   "metadata": {},
   "source": [
    "### Reflection Question\n",
    "\n",
    "Imagine you have a complicated posterior that you **can’t plot or integrate directly**,  \n",
    "but you can **sample** from it using MCMC.\n",
    "\n",
    "> What’s one way you could tell — just by looking at the samples whether your Markov chain has **“converged”** (i.e., is now exploring the true posterior rather than still wandering)?\n",
    "\n",
    "Write your answer in one or two sentences below the cell.  \n",
    "*(Hint: think of the analogy — what would a “well-mixed walker” look like?)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d3779a",
   "metadata": {},
   "source": [
    "Answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f7d7a2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
